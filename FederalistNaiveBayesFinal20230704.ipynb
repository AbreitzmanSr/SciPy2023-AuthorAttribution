{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Naive Bayes on Federalist Papers to identify author of 12 Disputed Federalist Papers\n",
    "#### It's unlikely that Jay is an author of disputed papers, so build Naive Bayes model using only Hamilton and Madison papers\n",
    "#### Breitzman 5/16/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#get Federalist papers previously stored in GutenbergFederalistPickle.ipynb\n",
    "with open('hamilton.pik', 'rb') as f:\n",
    "    hamilton = pickle.load(f)\n",
    "    \n",
    "with open('madison.pik', 'rb') as f:\n",
    "    madison = pickle.load(f)\n",
    "    \n",
    "with open('disputed.pik', 'rb') as f:\n",
    "    disputed = pickle.load(f)\n",
    "\n",
    "with open('joint.pik', 'rb') as f:\n",
    "    joint = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 14 3 12\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "kills = [',','.',\"''\",'',';','-',')','(']\n",
    "\n",
    "completeDict = {}  #dictionary containing any word mentioned in any of the Federalist papers and the number of Federalist Papers containing word\n",
    "hamiltonDicts = [] #list of dictionaries containing word freq for each of Hamilton's Federalist Papers\n",
    "madisonDicts = []\n",
    "disputedDicts = []\n",
    "jointDicts = []\n",
    "\n",
    "def getDocDict(str1):\n",
    "#returns a dictonary containing frequencies of any word in string\n",
    "#e.g. str1 = 'quick brown fox is quick.'\n",
    "# returns {quick:2, brown:1, fox:1, is:1}\n",
    "  x = {}\n",
    "  words = word_tokenize(str1.lower().strip())\n",
    "  for b in words:\n",
    "        if b in x:\n",
    "            x[b]+=1\n",
    "        else:\n",
    "            x[b]=1\n",
    "  return(x)\n",
    "\n",
    "for a in hamilton:\n",
    "    hamiltonDicts.append(getDocDict(a[1][0]))\n",
    "    \n",
    "for a in madison:\n",
    "    madisonDicts.append(getDocDict(a[1][0]))\n",
    "    \n",
    "for a in joint:\n",
    "    jointDicts.append(getDocDict(a[1][0]))\n",
    "    \n",
    "for a in disputed:\n",
    "    disputedDicts.append(getDocDict(a[1][0]))\n",
    "    \n",
    "print(len(hamiltonDicts),len(madisonDicts),len(jointDicts),len(disputedDicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8492 3967\n"
     ]
    }
   ],
   "source": [
    "completeDict = {} #dictionary containing every word along with \n",
    "                  #documeny frequency \n",
    "                  #(e.g. # of fed papers containing word)\n",
    "\n",
    "kills = [',','.',\"''\",'',';','-',')','(']\n",
    "authDicts = [hamiltonDicts,madisonDicts,jointDicts,disputedDicts]\n",
    "for authDict in authDicts:\n",
    "  for a in authDict:\n",
    "    for x in a:\n",
    "        if (x not in kills):\n",
    "         if x in completeDict:\n",
    "            completeDict[x]+=1\n",
    "         else:\n",
    "            completeDict[x]=1\n",
    "            \n",
    "trimDict = set()  #subset of completeDict that contains useful words\n",
    "for a in completeDict:\n",
    "    x = completeDict[a]\n",
    "    if (x >= 3 and x < 80):\n",
    "        trimDict.add(a)\n",
    "        \n",
    "print(len(completeDict),len(trimDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64314 27766\n"
     ]
    }
   ],
   "source": [
    "#build Naive Bayes Dictionaries for Hamilton, Madison\n",
    "hamiltonNBwordDicts = {}\n",
    "madisonNBwordDicts = {}\n",
    "\n",
    "for a in trimDict: #this is equivalent to Laplace Smoothing\n",
    "    hamiltonNBwordDicts[a] = madisonNBwordDicts[a] = 2\n",
    "    \n",
    "for dictionary in hamiltonDicts:\n",
    "    for word in dictionary:\n",
    "        if (word in trimDict):\n",
    "              hamiltonNBwordDicts[word]+=dictionary[word]\n",
    "            \n",
    "for dictionary in madisonDicts:\n",
    "    for word in dictionary:\n",
    "        if (word in trimDict):\n",
    "            if (word in madisonNBwordDicts):\n",
    "              madisonNBwordDicts[word]+=dictionary[word]\n",
    "            \n",
    "hamiltonNBdenom = madisonNBdenom = 0\n",
    "for x in hamiltonNBwordDicts:\n",
    "    hamiltonNBdenom += hamiltonNBwordDicts[x]\n",
    "for x in madisonNBwordDicts:\n",
    "    madisonNBdenom += madisonNBwordDicts[x]  \n",
    "    \n",
    "print(hamiltonNBdenom,madisonNBdenom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3967 3967 3967\n"
     ]
    }
   ],
   "source": [
    "print(len(hamiltonNBwordDicts),len(madisonNBwordDicts),len(trimDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watch 2 2\n",
      "entering 2 2\n",
      "septennial 2 2\n",
      "prompted 2 2\n",
      "abbe 2 2\n"
     ]
    }
   ],
   "source": [
    "for a in hamiltonNBwordDicts:\n",
    "    if (hamiltonNBwordDicts[a]<=2 and madisonNBwordDicts[a]<=2):\n",
    "        print(a,hamiltonNBwordDicts[a],madisonNBwordDicts[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltonNBwordDicts['upon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madisonNBwordDicts['upon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64314 27766\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "print(hamiltonNBdenom,madisonNBdenom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3967 1452\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for word in (trimDict):\n",
    "      if (not (hamiltonNBwordDicts[word]/hamiltonNBdenom < .0002 and\n",
    "          madisonNBwordDicts[word]/madisonNBdenom < .0002)):\n",
    "          vocab.add(word)\n",
    "      \n",
    "\n",
    "print(len(trimDict),len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% correct: 100.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#given a document return 'hamilton' if NaiveBayes prob \n",
    "#suggests Hamilton authored it. similarly return \n",
    "#'madison' if he is the likely author\n",
    "def NB_federalist_predict(docDict,vocab1=trimDict):\n",
    "  h_pr = m_pr = 0\n",
    "  for word in docDict:\n",
    "    if (word in vocab1):\n",
    "        h_pr += float(docDict[word])*(math.log(\n",
    "           hamiltonNBwordDicts[word]/hamiltonNBdenom))\n",
    "        m_pr += float(docDict[word])*(math.log(\n",
    "           madisonNBwordDicts[word]/madisonNBdenom))\n",
    "        \n",
    "  if (h_pr > m_pr):\n",
    "         return('hamilton')\n",
    "  else:\n",
    "         return('madison')\n",
    "    \n",
    "def check_accuracy(vocab1=trimDict):\n",
    "    right = wrong = 0\n",
    "    for a in hamiltonDicts:\n",
    "        if NB_federalist_predict(a,vocab1)=='hamilton':\n",
    "            right+=1\n",
    "        else:\n",
    "            wrong+=1\n",
    "\n",
    "    for a in madisonDicts:\n",
    "        if NB_federalist_predict(a,vocab1)=='madison':\n",
    "            right+=1\n",
    "        else:\n",
    "            wrong+=1\n",
    "    return([100*right/(right+wrong),right,wrong])\n",
    "    \n",
    "print('% correct:',check_accuracy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.0, 65, 0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.17269023851727464 5.790715263271626\n",
      "indebted 0.17269023851727464 5.790715263271626\n",
      "involves 0.14390853209772886 6.9488583159259525\n",
      "sphere 0.12951767888795596 7.72095368436217\n",
      "residence 0.16189709860994494 6.1767629474897365\n",
      "stamped 0.14390853209772886 6.9488583159259525\n",
      "consequently 0.1850252555542228 5.404667579053519\n",
      "kind 11.22486550362285 0.0890879271272558\n",
      "lesser 0.19187804279697182 5.211643736944464\n",
      "compilers 0.17269023851727464 5.790715263271626\n",
      "slaves 0.17269023851727464 5.790715263271626\n",
      "nomination 5.180707155518238 0.19302384210905427\n",
      "composing 0.09962898375996612 10.03723978967082\n",
      "courts 8.418649127717138 0.11878390283634108\n",
      "patriotic 0.17269023851727464 5.790715263271626\n",
      "democratic 0.17269023851727464 5.790715263271626\n",
      "transferred 0.17269023851727464 5.790715263271626\n",
      "intended 7.986923531423951 0.12520465434100816\n",
      "community 7.663129334204061 0.1304949918483747\n",
      "2. 0.17269023851727464 5.790715263271626\n",
      "democracy 0.07195426604886443 13.897716631851905\n",
      "pointing 0.17269023851727464 5.790715263271626\n",
      "chain 0.14390853209772886 6.9488583159259525\n",
      "surely 0.17269023851727464 5.790715263271626\n",
      "respectively 0.16189709860994494 6.1767629474897365\n",
      "-- 5.936226949031315 0.1684571712951746\n",
      "bind 0.17269023851727464 5.790715263271626\n",
      "while 8.202786329570543 0.1219097950162448\n",
      "enough 7.555197935130765 0.13235920601763718\n",
      "upon 17.940597001516863 0.05573950520796219\n",
      "speedy 0.17269023851727464 5.790715263271626\n",
      "readily 5.612432751811425 0.1781758542545116\n",
      "reform 0.09593902139848591 10.423287473888928\n",
      "alloy 0.14390853209772886 6.9488583159259525\n",
      "confederation 0.18935333170753796 5.281132320103724\n",
      "assumed 0.09593902139848591 10.423287473888928\n",
      "violating 0.14390853209772886 6.9488583159259525\n",
      "complied 0.17269023851727464 5.790715263271626\n",
      "obviated 0.17269023851727464 5.790715263271626\n",
      "administering 0.14390853209772886 6.9488583159259525\n",
      "drawing 0.17269023851727464 5.790715263271626\n",
      "pronounced 0.1850252555542228 5.404667579053519\n",
      "recommended 0.16189709860994494 6.1767629474897365\n",
      "enlarge 0.1233501703694819 8.107001368580276\n",
      "jury 6.216848586621887 0.1608532017575452\n",
      "although 0.14390853209772883 6.948858315925953\n",
      "cantons 0.17269023851727464 5.790715263271626\n",
      "intermixed 0.17269023851727464 5.790715263271626\n",
      "annually 0.17269023851727464 5.790715263271626\n",
      "commonly 5.180707155518238 0.19302384210905427\n",
      "universally 0.17269023851727464 5.790715263271626\n",
      "1. 0.1233501703694819 8.107001368580276\n",
      "eyes 0.1850252555542228 5.404667579053519\n",
      "enumeration 0.19925796751993224 5.01861989483541\n",
      "works 0.17269023851727464 5.790715263271626\n",
      "matter 5.180707155518238 0.19302384210905427\n",
      "disregarded 0.17269023851727464 5.790715263271626\n",
      "indirectly 0.10793139907329664 9.265144421234604\n",
      "crushed 0.17269023851727464 5.790715263271626\n",
      "whilst 0.0925126277771114 10.809335158107038\n",
      "novelty 0.17269023851727464 5.790715263271626\n",
      "term 0.1269781165568196 7.875372758049412\n",
      "derives 0.17269023851727464 5.790715263271626\n",
      "inconveniency 0.17269023851727464 5.790715263271626\n",
      "unanimous 0.1233501703694819 8.107001368580276\n",
      "department 0.15631444003718825 6.397361624185797\n",
      "obscurity 0.1850252555542228 5.404667579053519\n",
      "relief 0.14390853209772883 6.948858315925953\n",
      "dishonorable 0.17269023851727464 5.790715263271626\n",
      "indispensably 0.14390853209772886 6.9488583159259525\n",
      "function 0.17269023851727464 5.790715263271626\n",
      "including 0.17269023851727464 5.790715263271626\n",
      "coin 0.10158249324545568 9.844215947561764\n"
     ]
    }
   ],
   "source": [
    "interesting = []\n",
    "for i,a in enumerate(trimDict):\n",
    "    h1 = hamiltonNBwordDicts[a]/hamiltonNBdenom\n",
    "    m1 = madisonNBwordDicts[a]/madisonNBdenom\n",
    "    if (m1/h1 > 5 or h1/m1 > 5):\n",
    "      print(a,h1/m1,m1/h1)\n",
    "      interesting.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.17269023851727464 5.790715263271626\n",
      "indebted 0.17269023851727464 5.790715263271626\n",
      "involves 0.14390853209772886 6.9488583159259525\n",
      "sphere 0.12951767888795596 7.72095368436217\n",
      "residence 0.16189709860994494 6.1767629474897365\n",
      "stamped 0.14390853209772886 6.9488583159259525\n",
      "consequently 0.1850252555542228 5.404667579053519\n",
      "kind 11.22486550362285 0.0890879271272558\n",
      "lesser 0.19187804279697182 5.211643736944464\n",
      "compilers 0.17269023851727464 5.790715263271626\n",
      "slaves 0.17269023851727464 5.790715263271626\n",
      "nomination 5.180707155518238 0.19302384210905427\n",
      "composing 0.09962898375996612 10.03723978967082\n",
      "courts 8.418649127717138 0.11878390283634108\n",
      "patriotic 0.17269023851727464 5.790715263271626\n",
      "democratic 0.17269023851727464 5.790715263271626\n",
      "transferred 0.17269023851727464 5.790715263271626\n",
      "intended 7.986923531423951 0.12520465434100816\n",
      "community 7.663129334204061 0.1304949918483747\n",
      "democracy 0.07195426604886443 13.897716631851905\n",
      "pointing 0.17269023851727464 5.790715263271626\n",
      "chain 0.14390853209772886 6.9488583159259525\n",
      "surely 0.17269023851727464 5.790715263271626\n",
      "respectively 0.16189709860994494 6.1767629474897365\n",
      "bind 0.17269023851727464 5.790715263271626\n",
      "while 8.202786329570543 0.1219097950162448\n",
      "enough 7.555197935130765 0.13235920601763718\n",
      "upon 17.940597001516863 0.05573950520796219\n",
      "speedy 0.17269023851727464 5.790715263271626\n",
      "readily 5.612432751811425 0.1781758542545116\n",
      "reform 0.09593902139848591 10.423287473888928\n",
      "alloy 0.14390853209772886 6.9488583159259525\n",
      "confederation 0.18935333170753796 5.281132320103724\n",
      "assumed 0.09593902139848591 10.423287473888928\n",
      "violating 0.14390853209772886 6.9488583159259525\n",
      "complied 0.17269023851727464 5.790715263271626\n",
      "obviated 0.17269023851727464 5.790715263271626\n",
      "administering 0.14390853209772886 6.9488583159259525\n",
      "drawing 0.17269023851727464 5.790715263271626\n",
      "pronounced 0.1850252555542228 5.404667579053519\n",
      "recommended 0.16189709860994494 6.1767629474897365\n",
      "enlarge 0.1233501703694819 8.107001368580276\n",
      "jury 6.216848586621887 0.1608532017575452\n",
      "although 0.14390853209772883 6.948858315925953\n",
      "cantons 0.17269023851727464 5.790715263271626\n",
      "intermixed 0.17269023851727464 5.790715263271626\n",
      "annually 0.17269023851727464 5.790715263271626\n",
      "commonly 5.180707155518238 0.19302384210905427\n",
      "universally 0.17269023851727464 5.790715263271626\n",
      "eyes 0.1850252555542228 5.404667579053519\n",
      "enumeration 0.19925796751993224 5.01861989483541\n",
      "works 0.17269023851727464 5.790715263271626\n",
      "matter 5.180707155518238 0.19302384210905427\n",
      "disregarded 0.17269023851727464 5.790715263271626\n",
      "indirectly 0.10793139907329664 9.265144421234604\n",
      "crushed 0.17269023851727464 5.790715263271626\n",
      "whilst 0.0925126277771114 10.809335158107038\n",
      "novelty 0.17269023851727464 5.790715263271626\n",
      "term 0.1269781165568196 7.875372758049412\n",
      "derives 0.17269023851727464 5.790715263271626\n",
      "inconveniency 0.17269023851727464 5.790715263271626\n",
      "unanimous 0.1233501703694819 8.107001368580276\n",
      "department 0.15631444003718825 6.397361624185797\n",
      "obscurity 0.1850252555542228 5.404667579053519\n",
      "relief 0.14390853209772883 6.948858315925953\n",
      "dishonorable 0.17269023851727464 5.790715263271626\n",
      "indispensably 0.14390853209772886 6.9488583159259525\n",
      "function 0.17269023851727464 5.790715263271626\n",
      "including 0.17269023851727464 5.790715263271626\n",
      "coin 0.10158249324545568 9.844215947561764\n"
     ]
    }
   ],
   "source": [
    "kills2 = ['--','1.','2.']\n",
    "interesting = []\n",
    "for i,a in enumerate(trimDict):\n",
    "    h1 = hamiltonNBwordDicts[a]/hamiltonNBdenom\n",
    "    m1 = madisonNBwordDicts[a]/madisonNBdenom\n",
    "    if (m1/h1 > 5 or m1/h1 <.2):\n",
    "     if (a not in kills2):\n",
    "      print(a,h1/m1,m1/h1)\n",
    "      interesting.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "small10 = ['upon','on','very','natural','concurrent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "small11 = ['upon','against','whilst','inhabitants','dismission','within']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallVocab2 = ['obviated','patriotic','lesser','composing','although','whilst','consequently','nomination','enough','while','inconveniency','sphere','upon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% accuracy\n",
      "disputed papers: madison:12, hamilton:0\n",
      "\n",
      "['although', 'composing', 'involves', 'confederation', 'upon']\n",
      "100.0% accuracy\n",
      "disputed papers: madison:12, hamilton:0\n",
      "\n",
      "['although', 'obviated', 'composing', 'whilst', 'consequently', 'upon']\n",
      "96.92307692307692% accuracy\n",
      "disputed papers: madison:12, hamilton:0\n",
      "\n",
      "['against', 'within', 'inhabitants', 'whilst', 'powers', 'upon', 'while']\n",
      "100.0% accuracy\n",
      "disputed papers: madison:12, hamilton:0\n",
      "\n",
      "['against', 'upon', 'whilst', 'inhabitants', 'within']\n",
      "96.92307692307692% accuracy\n",
      "disputed papers: madison:12, hamilton:0\n",
      "\n",
      "['against', 'within', 'inhabitants', 'whilst', 'upon']\n",
      "96.92307692307692% accuracy\n",
      "disputed papers: madison:12, hamilton:0\n",
      "\n",
      "['against', 'while', 'whilst', 'upon', 'on']\n",
      "96.92307692307692% accuracy\n",
      "disputed papers: madison:12, hamilton:0\n",
      "\n",
      "['concurrent', 'upon', 'on', 'very', 'natural']\n",
      "98.46153846153847% accuracy\n",
      "disputed papers: madison:12, hamilton:0\n",
      "\n",
      "['while', 'upon', 'on', 'inconveniency']\n",
      "95.38461538461539% accuracy\n",
      "disputed papers: madison:12, hamilton:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#the following checks accuracy on the training set and then\n",
    "#identifies how many of the disputed papers are by each author\n",
    "def report1(words=trimDict):\n",
    "    if (len(words)<10):\n",
    "        print(words)\n",
    "    print(str(check_accuracy(words)[0])+'% accuracy')\n",
    "    madison = hamilton = 0\n",
    "    for a in disputedDicts:\n",
    "        if (NB_federalist_predict(a,words)=='madison'):\n",
    "            madison+=1\n",
    "        else:\n",
    "            hamilton+=1\n",
    "    print(\"disputed papers: madison:\"+str(madison)+\n",
    "          ', hamilton:'+str(hamilton)+'\\n')\n",
    "    \n",
    "report1(interesting)\n",
    "report1(['although','composing','involves',\n",
    "         'confederation','upon'])\n",
    "report1(['although','obviated','composing',\n",
    "         'whilst','consequently','upon'])\n",
    "report1(['against','within','inhabitants',\n",
    "         'whilst','powers','upon','while'])\n",
    "report1(['against','upon','whilst',\n",
    "         'inhabitants','within'])\n",
    "report1(['against','within','inhabitants',\n",
    "         'whilst','upon'])\n",
    "report1(['against','while','whilst','upon','on'])\n",
    "report1(['concurrent','upon','on',\n",
    "         'very','natural'])\n",
    "report1(['while','upon','on','inconveniency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
